{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import sknetwork\n",
    "from IPython.display import display,SVG,clear_output\n",
    "from collections import Counter\n",
    "import os\n",
    "import graph_tool as gt\n",
    "import itertools\n",
    "from graph_tool.all import *\n",
    "import pyintergraph as pyg\n",
    "import scipy.sparse as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cython code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "\n",
    "cimport cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "import graph_tool as gt\n",
    "from graph_tool.all import *\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import random\n",
    "from cython.view cimport array as cvarray\n",
    "from libc.math cimport isnan\n",
    "cdef extern from \"math.h\":\n",
    "    double log(double x)\n",
    "    double sinh(double x)\n",
    "    double cosh(double x)\n",
    "    double exp(double x)\n",
    "    double pow(double x, double y)\n",
    "    double log1p(double x)\n",
    "    double sqrt(double x)\n",
    "    double fabs (double x)\n",
    "    double lgamma (double x)\n",
    "    \n",
    "cdef extern from \"<algorithm>\" namespace \"std\" nogil:\n",
    "    Iter find[Iter, T](Iter first, Iter last, const T& value)\n",
    "    OutputIter merge[InputIter1, InputIter2, OutputIter] (InputIter1 first1, InputIter1 last1,\n",
    "                        InputIter2 first2, InputIter2 last2,\n",
    "                        OutputIter result)\n",
    "   \n",
    "    \n",
    "from libc.stdlib cimport rand, RAND_MAX, srand, malloc, free\n",
    "from libc.math cimport floor, ceil\n",
    "from cython.parallel import prange\n",
    "from libcpp.map cimport map as cpp_map\n",
    "from libcpp.vector cimport vector as cpp_vector\n",
    "from libcpp.unordered_set cimport unordered_set\n",
    "from libcpp.utility cimport pair as cpp_pair\n",
    "from cython.operator cimport dereference as deref\n",
    "from cython.operator cimport preincrement as preinc  \n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef double random_uniform() nogil:\n",
    "    \"\"\"\n",
    "    uniform rng\n",
    "    \"\"\"\n",
    "    cdef double r = rand()\n",
    "    return r / RAND_MAX\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef long random_int(long a,long b) nogil:\n",
    "    \"\"\"\n",
    "    uniform rng for integer within [a,b]\n",
    "    \"\"\"\n",
    "    b += 1\n",
    "    return int(a + random_uniform()*(b-a))\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef double zero_lgamma(double a):\n",
    "    \"\"\"\n",
    "    log gamma function\n",
    "    \"\"\"\n",
    "    if a == 0.:\n",
    "        return 0.\n",
    "    else:\n",
    "        return lgamma(a)\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef double zero_log(double a):\n",
    "    \"\"\"\n",
    "    log(x), with log(0) set to 0\n",
    "    \"\"\"\n",
    "    if a == 0.:\n",
    "        return 0.\n",
    "    else:\n",
    "        return log(a)\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef double log_choose(long N,long K):\n",
    "    \"\"\"\n",
    "    log(N choose K)\n",
    "    \"\"\"\n",
    "    cdef double Nd = float(N), Kd = float(K)\n",
    "    return zero_lgamma(Nd+1.) - zero_lgamma(Nd+1.-Kd) - zero_lgamma(Kd+1.)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef double log_multinomial(long N,cpp_vector[double] counts):\n",
    "    \"\"\"\n",
    "    log oof multinomial coefficient, with vector 'counts' giving sizes of bins in the denominator\n",
    "    \"\"\"\n",
    "    cdef double logcoef,c\n",
    "    logcoef = lgamma(N+1.)\n",
    "    for c in counts:\n",
    "        logcoef -= zero_lgamma(c+1.)\n",
    "    return logcoef\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef unordered_set[long] unique(long[:] arr):\n",
    "    \"\"\"\n",
    "    find unique elements in 'arr'\n",
    "    \"\"\"\n",
    "    cdef long length = arr.shape[0]\n",
    "    cdef unordered_set[long] uniq\n",
    "    cdef long i,val\n",
    "    for i in range(length):\n",
    "        val = arr[i]\n",
    "        if (uniq.find(val) == uniq.end()):\n",
    "            uniq.insert(val)\n",
    "    return uniq\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef cpp_map[long,double] counter(long[:] arr):\n",
    "    \"\"\"\n",
    "    get counts of unique elements in 'arr' (as with collections.Counter)\n",
    "    \"\"\"\n",
    "    cdef long length = arr.shape[0]\n",
    "    cdef cpp_map[long,double] counts \n",
    "    cdef unordered_set[long] unique_elements\n",
    "    cdef long i,val\n",
    "    for i in range(length):\n",
    "        val = arr[i]\n",
    "        if (unique_elements.find(val) == unique_elements.end()):\n",
    "            unique_elements.insert(val)\n",
    "            counts[val] = 1.\n",
    "        else:\n",
    "            counts[val] += 1.   \n",
    "    return counts\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef long categorical(double[:] ps):\n",
    "    \"\"\"\n",
    "    categorical random draw with probability vector ps\n",
    "    \"\"\"\n",
    "    cdef long i = 0\n",
    "    cdef double rand = random_uniform()\n",
    "    cdef double cmf = ps[0]\n",
    "    \n",
    "    while cmf < rand:\n",
    "        cmf += ps[i]\n",
    "        i += 1\n",
    "    \n",
    "    return i\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef unordered_set[long] set_merge(unordered_set[long] s1,unordered_set[long] s2):\n",
    "    \"\"\"\n",
    "    merge sets together\n",
    "    \"\"\"\n",
    "    cdef unordered_set[long] s\n",
    "    cdef long i\n",
    "    if s1.size() > s2.size():\n",
    "        s = s1\n",
    "        for i in s2:\n",
    "            s.insert(i)  \n",
    "    else:\n",
    "        s = s2\n",
    "        for i in s1:\n",
    "            s.insert(i)\n",
    "        \n",
    "    return s\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cpdef double MI(long[:] part1,long[:] part2):\n",
    "    \"\"\"\n",
    "    mutual information between partitions 'part1' and 'part2'\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef long i,r,s,N = part1.shape[0],ind \n",
    "    cdef double mi,log_omega,w,nu,mu,sum_x2,sum_y2,sum_logx,sum_logy,frac,n = float(N)\n",
    "    cdef unordered_set[long] uniq_p1 = unique(part1)\n",
    "    cdef unordered_set[long] uniq_p2 = unique(part2)\n",
    "    cdef long R = uniq_p1.size(),S = uniq_p2.size()\n",
    "    cdef double R_fl = float(R), S_fl = float(S)\n",
    "    cdef double[:,:] cont = cvarray(shape=(R,S), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] a = cvarray(shape=(R,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] b = cvarray(shape=(S,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef cpp_map[long,long] ind2r\n",
    "    cdef cpp_map[long,long] ind2s\n",
    "    cdef double[:] x = cvarray(shape=(R,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] y = cvarray(shape=(S,), itemsize=sizeof(double), format=\"d\")\n",
    "    \n",
    "    ind = 0\n",
    "    for i in uniq_p1:\n",
    "        ind2r[i] = ind\n",
    "        ind += 1   \n",
    "    ind = 0\n",
    "    for i in uniq_p2:\n",
    "        ind2s[i] = ind\n",
    "        ind += 1  \n",
    "    for r in range(R):\n",
    "        a[r] = 0.\n",
    "        for s in range(S):\n",
    "            b[s] = 0.\n",
    "            cont[r,s] = 0.\n",
    "    for i in range(N):\n",
    "        r = ind2r[part1[i]]\n",
    "        s = ind2s[part2[i]]\n",
    "        cont[r,s] += 1.\n",
    "        a[r] += 1.\n",
    "        b[s] += 1.\n",
    "    \n",
    "    mi = 0.\n",
    "    for r in range(R):\n",
    "        for s in range(S):\n",
    "            mi += (cont[r,s]/n)*zero_log(n*cont[r,s]/a[r]/b[s])\n",
    "            \n",
    "    return mi\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cpdef double RMI(long[:] part1,long[:] part2):\n",
    "    \"\"\"\n",
    "    reduced mutual information between partitions 'part1' and 'part2'\n",
    "    computes standard mutual information and subtracts off correction for information in contingency table\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef long i,r,s,N = part1.shape[0],ind \n",
    "    cdef double mi,log_omega,w,nu,mu,sum_x2,sum_y2,sum_logx,sum_logy,frac,n = float(N)\n",
    "    cdef unordered_set[long] uniq_p1 = unique(part1)\n",
    "    cdef unordered_set[long] uniq_p2 = unique(part2)\n",
    "    cdef long R = uniq_p1.size(),S = uniq_p2.size()\n",
    "    cdef double R_fl = float(R), S_fl = float(S)\n",
    "    cdef double[:,:] cont = cvarray(shape=(R,S), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] a = cvarray(shape=(R,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] b = cvarray(shape=(S,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef cpp_map[long,long] ind2r\n",
    "    cdef cpp_map[long,long] ind2s\n",
    "    cdef double[:] x = cvarray(shape=(R,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] y = cvarray(shape=(S,), itemsize=sizeof(double), format=\"d\")\n",
    "    \n",
    "    ind = 0\n",
    "    for i in uniq_p1:\n",
    "        ind2r[i] = ind\n",
    "        ind += 1   \n",
    "    ind = 0\n",
    "    for i in uniq_p2:\n",
    "        ind2s[i] = ind\n",
    "        ind += 1  \n",
    "    for r in range(R):\n",
    "        a[r] = 0.\n",
    "        for s in range(S):\n",
    "            b[s] = 0.\n",
    "            cont[r,s] = 0.\n",
    "    for i in range(N):\n",
    "        r = ind2r[part1[i]]\n",
    "        s = ind2s[part2[i]]\n",
    "        cont[r,s] += 1.\n",
    "        a[r] += 1.\n",
    "        b[s] += 1.\n",
    "    \n",
    "    mi = 0.\n",
    "    for r in range(R):\n",
    "        for s in range(S):\n",
    "            mi += (cont[r,s]/n)*zero_log(n*cont[r,s]/a[r]/b[s])\n",
    "            \n",
    "    w = n/(n+0.5*R_fl*S_fl)\n",
    "    sum_x2 = 0.\n",
    "    sum_y2 = 0.\n",
    "    sum_logx = 0.\n",
    "    sum_logy = 0.\n",
    "    for r in range(R):\n",
    "        x[r] = (1.-w)/R_fl + w*a[r]/n\n",
    "        sum_x2 += x[r]*x[r]\n",
    "        sum_logx += zero_log(x[r])\n",
    "    for s in range(S):\n",
    "        y[s] = (1.-w)/S_fl + w*b[s]/n\n",
    "        sum_y2 += y[s]*y[s]\n",
    "        sum_logy += zero_log(y[s])\n",
    "    nu = (S_fl+1.)/(S_fl*sum_x2) - 1./S_fl\n",
    "    mu = (R_fl+1.)/(R_fl*sum_y2) - 1./R_fl\n",
    "    log_omega = (R_fl-1.)*(S_fl-1.)*zero_log(n+0.5*R_fl*S_fl) \\\n",
    "                 + 0.5*(R_fl+nu-2.)*sum_logy + 0.5*(S_fl+mu-2.)*sum_logx \\\n",
    "                 + 0.5*(lgamma(mu*R_fl)+lgamma(nu*S_fl) \\\n",
    "                 - R_fl*(lgamma(S_fl)+lgamma(mu)) - S_fl*(lgamma(R_fl)+lgamma(nu)))\n",
    "\n",
    "    return mi - log_omega/n\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cpdef double VI(long[:] part1,long[:] part2):\n",
    "    \"\"\"\n",
    "    variation of information between partitions 'part1' and 'part2' \n",
    "    \"\"\"\n",
    "    \n",
    "    cdef long i,r,s,N = part1.shape[0],ind \n",
    "    cdef double vi,frac,n = float(N)\n",
    "    cdef unordered_set[long] uniq_p1 = unique(part1)\n",
    "    cdef unordered_set[long] uniq_p2 = unique(part2)\n",
    "    cdef long R = uniq_p1.size(),S = uniq_p2.size()\n",
    "    cdef double[:,:] cont = cvarray(shape=(R,S), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] a = cvarray(shape=(R,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef double[:] b = cvarray(shape=(S,), itemsize=sizeof(double), format=\"d\")\n",
    "    cdef cpp_map[long,long] ind2r\n",
    "    cdef cpp_map[long,long] ind2s\n",
    "    \n",
    "    ind = 0\n",
    "    for i in uniq_p1:\n",
    "        ind2r[i] = ind\n",
    "        ind += 1   \n",
    "    ind = 0\n",
    "    for i in uniq_p2:\n",
    "        ind2s[i] = ind\n",
    "        ind += 1  \n",
    "    for r in range(R):\n",
    "        a[r] = 0.\n",
    "        for s in range(S):\n",
    "            b[s] = 0.\n",
    "            cont[r,s] = 0.\n",
    "    for i in range(N):\n",
    "        r = ind2r[part1[i]]\n",
    "        s = ind2s[part2[i]]\n",
    "        cont[r,s] += 1.\n",
    "        a[r] += 1.\n",
    "        b[s] += 1.\n",
    "    \n",
    "    vi = 0.\n",
    "    for r in range(R):\n",
    "        for s in range(S):\n",
    "            vi -= (cont[r,s]/n)*(zero_log(cont[r,s]/a[r]) + zero_log(cont[r,s]/b[s]))\n",
    "\n",
    "    return vi\n",
    "\n",
    "  \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)\n",
    "cdef class clustering_state():\n",
    "    \n",
    "    \"\"\"\n",
    "    class for state updated during clustering procedure\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef long num_mcs,n_samples,N,K,Kprior,MItype,mode_info_type\n",
    "    cdef long[:] mode_labels\n",
    "    cdef long[:,:] partitions\n",
    "    cdef double DL,mode_scale,num_mcs_float,N_float,n_samples_float,Lambda\n",
    "    cdef double[:] H_arr,energies,partition_entropies,num_groups_arr,nps\n",
    "    cdef double[:,:] CE_matrix,VI_matrix\n",
    "    cdef unordered_set[long] modes\n",
    "    cdef cpp_map[long,unordered_set[long]] clusters\n",
    "    cdef cpp_map[long,double] cluster_sizes\n",
    "    \n",
    "    def __init__(self,long[:,:] partitions,double[:] energies,long num_mcs,double Lambda,\\\n",
    "                                 long Kprior,long MItype,long mode_info_type):\n",
    "        \"\"\"\n",
    "        initialize class attributes\n",
    "        inputs:\n",
    "            'partitions': S by N vector of partitions\n",
    "            'energies': length S vector of log probabilities of vectors in 'partitions'\n",
    "            'num_mcs': number of local MCMC steps to perform for estimating mode of cluster\n",
    "            'Lambda': linear penalty for K. set to zero for standard description length\n",
    "            'Kprior': 0 gives no penalty on K; 1 gives linear penalty on K (used in paper); 2 gives log(K) penalty\n",
    "            'MItype': 0 gives regular mutual information, 1 gives reduced mutual information (used in paper)\n",
    "            'mode_info_type': 0 gives entropy penalty (used in paper); 1 gives less efficient fixed-length code \n",
    "        \"\"\"\n",
    "\n",
    "        self.partitions = partitions\n",
    "        self.energies = energies\n",
    "        self.num_mcs = num_mcs\n",
    "        self.n_samples = int(self.partitions.shape[0])\n",
    "        self.N = int(self.partitions.shape[1])\n",
    "        self.H_arr = (np.ones(self.n_samples)*-1).astype('float')\n",
    "        self.CE_matrix = (np.ones((self.n_samples,self.n_samples))*-1).astype('float')\n",
    "        self.VI_matrix = (np.ones((self.n_samples,self.n_samples))*-1).astype('float')\n",
    "        self.mode_labels = np.zeros(self.n_samples).astype('int')\n",
    "        self.partition_entropies = np.array([gt.inference.mutual_information(p,p) for p in np.array(self.partitions).tolist()]).astype('float')\n",
    "        self.nps = np.array([len(np.unique(p)) for p in np.array(self.partitions).tolist()]).astype('float')\n",
    "        self.num_mcs_float = float(self.num_mcs)\n",
    "        self.N_float = float(self.N)\n",
    "        self.n_samples_float = float(self.n_samples)\n",
    "        self.num_groups_arr = np.array([len(np.unique(p)) for p in np.array(self.partitions).tolist()]).astype('float')\n",
    "        self.Lambda = Lambda\n",
    "        self.Kprior = Kprior\n",
    "        self.MItype = MItype\n",
    "        self.mode_info_type = mode_info_type\n",
    "       \n",
    "    cdef double CE_w_mat(self,long p1ind,long p2ind):\n",
    "        \"\"\"\n",
    "        compute conditional entropy between partitions with indices 'p1ind' and 'p2ind'\n",
    "        saves results in matrix 'self.CE_matrix' to avoid redundant computations\n",
    "        \"\"\"\n",
    "        \n",
    "        cdef double H1,rmi\n",
    "        if self.CE_matrix[p1ind,p2ind] == -1: \n",
    "            if p1ind == p2ind:\n",
    "                self.CE_matrix[p1ind,p2ind] = 0.\n",
    "            else:   \n",
    "                if self.MItype == 0:\n",
    "                    rmi = MI(self.partitions[p1ind,:],self.partitions[p2ind,:])\n",
    "                else:\n",
    "                    rmi = RMI(self.partitions[p1ind,:],self.partitions[p2ind,:])\n",
    "                H1 = self.partition_entropies[p1ind]\n",
    "                self.CE_matrix[p1ind,p2ind] = self.N_float*(H1 - rmi)/self.n_samples_float\n",
    "        return self.CE_matrix[p1ind,p2ind]\n",
    "    \n",
    "    cdef double VI_w_mat(self,long p1ind,long p2ind):\n",
    "        \"\"\"\n",
    "        compute variation of information between partitions with indices 'p1ind' and 'p2ind'\n",
    "        not used in algorithm in paper\n",
    "        \"\"\"\n",
    "        cdef double vi\n",
    "        if self.VI_matrix[p1ind,p2ind] == -1: \n",
    "            vi = VI(self.partitions[p1ind,:],self.partitions[p2ind,:])\n",
    "            self.VI_matrix[p1ind,p2ind] = vi\n",
    "        return self.VI_matrix[p1ind,p2ind]\n",
    "    \n",
    "    cdef long closest_mode(self,long p1ind,unordered_set[long] mode_choices):\n",
    "        \"\"\"\n",
    "        find the closest mode to partition with index 'p1ind', out of the set 'mode_choices' (which are partition indices)\n",
    "        \"\"\"\n",
    "        cdef long m \n",
    "        cdef double min_dist = 1000000000000.,dist\n",
    "        cdef long best_mode\n",
    "        if (mode_choices.find(p1ind) != mode_choices.end()):\n",
    "            return p1ind\n",
    "        for m in mode_choices:\n",
    "            dist = self.CE_w_mat(p1ind,m)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_mode = m      \n",
    "        return best_mode\n",
    "    \n",
    "    cdef double cluster_DL(self,long mode,unordered_set[long] cluster,long approx):\n",
    "        \"\"\"\n",
    "        compute description length contribution from single cluster with mode of index 'mode'\n",
    "        uses MCMC with 'self.num_mcs' samples to estimate the sum of conditional entropies if approx = 1, else is exact\n",
    "        \"\"\"\n",
    "        cdef long clen = cluster.size()\n",
    "        cdef double clen_float = float(clen)\n",
    "        cdef double mean = 0.,res\n",
    "        cdef long i  \n",
    "        cdef cpp_vector[long] cluster_vec\n",
    "        for i in cluster:\n",
    "            cluster_vec.push_back(i)\n",
    "        if approx == 1:\n",
    "            for i in range(self.num_mcs):\n",
    "                mean += self.CE_w_mat(cluster_vec[i],mode)/self.num_mcs_float   \n",
    "        else:\n",
    "            for i in cluster:\n",
    "                mean += self.CE_w_mat(i,mode)/clen_float\n",
    "        if self.mode_info_type == 0:\n",
    "            res = mean*clen_float + self.partition_entropies[mode]*self.N_float/self.n_samples_float\n",
    "        else:\n",
    "            res = mean*clen_float + self.N_float/self.n_samples_float*log(self.nps[mode])\n",
    "        return res\n",
    "    \n",
    "    cdef double sizes_DL(self,long KK,cpp_vector[double] sizes):\n",
    "        \"\"\"\n",
    "        compute description length contributions from number and size of clusters\n",
    "        'KK' is current number of clusters, and 'sizes' is sizes of clusters\n",
    "        \"\"\"\n",
    "        cdef double dl = 0.,s\n",
    "        cdef double KKD = float(KK)\n",
    "        for s in sizes:\n",
    "            dl -= (s/self.n_samples_float)*zero_log(s/self.n_samples_float)\n",
    "        if self.Kprior == 0:\n",
    "            return dl\n",
    "        elif self.Kprior == 1:\n",
    "            return dl + KKD*self.Lambda\n",
    "        elif self.Kprior == 2:\n",
    "            return log(KKD)\n",
    "    \n",
    "    cdef long mc_centroid(self,unordered_set[long] cluster):\n",
    "        \"\"\"\n",
    "        estimate mode of 'cluster'\n",
    "        if size of cluster is less than 'self.num_mcs', computes mode exactly, otherwise estimates with MCMC\n",
    "        \"\"\"\n",
    "        cdef long clen = cluster.size()\n",
    "        cdef long i,approx\n",
    "        cdef double min_obj = 1000000000000000.,obj\n",
    "        cdef long best_centroid\n",
    "        if clen < self.num_mcs:\n",
    "            approx = 0\n",
    "        else:\n",
    "            approx = 1 \n",
    "        for i in cluster:\n",
    "            obj = self.cluster_DL(i,cluster,approx)\n",
    "            if obj < min_obj:\n",
    "                min_obj = obj\n",
    "                best_centroid = i     \n",
    "        return best_centroid\n",
    "    \n",
    "    cdef void initalize_cluster_data(self,long num_init_modes,long initial_runs):\n",
    "        \"\"\"\n",
    "        initializes modes given 'num_init_modes' initial modes K0, and some number of initial runs for which we run K0-medoids\n",
    "        \"\"\"\n",
    "        cdef unordered_set[long] previous_modes\n",
    "        cdef unordered_set[long] cluster\n",
    "        cdef unordered_set[double] mode_approx_energies\n",
    "        cdef long[:] perm_partitions = np.random.permutation(range(self.n_samples)).astype('int')\n",
    "        cdef double[:] approx_energies = np.array([np.round(e,5) for e in self.energies]).astype('float')\n",
    "        cdef long index,best,p1ind,old\n",
    "        cdef unordered_set[long] dummy\n",
    "         \n",
    "        self.K = num_init_modes\n",
    "        \n",
    "        for index in range(self.n_samples):\n",
    "            p1ind = perm_partitions[index]\n",
    "            if (mode_approx_energies.find(self.energies[p1ind]) == mode_approx_energies.end()):\n",
    "                if (self.modes.size() < num_init_modes):\n",
    "                    self.modes.insert(p1ind)\n",
    "                    mode_approx_energies.insert(self.energies[p1ind])\n",
    "\n",
    "        for p1ind in self.modes:\n",
    "            self.clusters[p1ind] = dummy \n",
    "            \n",
    "        for p1ind in range(self.n_samples):\n",
    "            best = self.closest_mode(p1ind,self.modes)\n",
    "            self.clusters[best].insert(p1ind)\n",
    "            self.mode_labels[p1ind] = best\n",
    "        \n",
    "        for index in range(initial_runs):\n",
    "         \n",
    "            previous_modes = self.modes\n",
    "            for m in previous_modes:\n",
    "                cluster = self.clusters[m]\n",
    "                best = self.mc_centroid(cluster)            \n",
    "                for p1ind in cluster:\n",
    "                    self.mode_labels[p1ind] = best\n",
    "                self.clusters.erase(m)\n",
    "                self.modes.erase(m)\n",
    "                self.clusters[best] = cluster\n",
    "                self.modes.insert(best)\n",
    "                \n",
    "            for p1ind in range(self.n_samples):\n",
    "                best = self.closest_mode(p1ind,self.modes)\n",
    "                old = self.mode_labels[p1ind]\n",
    "                self.clusters[old].erase(p1ind)\n",
    "                self.clusters[best].insert(p1ind)\n",
    "                self.mode_labels[p1ind] = best\n",
    "         \n",
    "        for m in self.modes:\n",
    "            self.cluster_sizes[m] = float(self.clusters[m].size())\n",
    "            \n",
    "    cdef void compute_full_DL(self):\n",
    "        \"\"\"\n",
    "        compute full description length of 'clustering_state' object\n",
    "        \"\"\"\n",
    "        cdef cpp_vector[double] sizes\n",
    "        cdef long m        \n",
    "        self.DL = 0.\n",
    "        for m in self.modes:\n",
    "            sizes.push_back(self.cluster_sizes[m])\n",
    "            self.DL += self.cluster_DL(m,self.clusters[m],0)\n",
    "        self.DL += self.sizes_DL(self.K,sizes)\n",
    "                \n",
    "    cdef void initialize_mode_scale(self,double dist_percentile,double manual_mode_scale):\n",
    "        \"\"\"\n",
    "        determine scale for which to separate two modes (to avoid them becoming too close together)\n",
    "        not used in paper algorithm\n",
    "        \"\"\"\n",
    "        cdef long p1,p2,i,num_rands = 10000\n",
    "        cdef double[:] dists = cvarray(shape=(num_rands,), itemsize=sizeof(double), format=\"d\")\n",
    "        if dist_percentile != -1.:\n",
    "            for i in range(num_rands):\n",
    "                p1 = random_int(0,self.n_samples-1)\n",
    "                p2 = random_int(0,self.n_samples-1)\n",
    "                dists[i] = self.VI_w_mat(p1,p2)\n",
    "            self.mode_scale = np.percentile(np.array(dists),dist_percentile) \n",
    "        elif manual_mode_scale != -1.:\n",
    "            self.mode_scale = manual_mode_scale\n",
    "            \n",
    "    cdef long closest_mode_move(self,long i):\n",
    "        \"\"\"\n",
    "        perform move of type 1 for partition indexed 'i' \n",
    "        \"\"\"\n",
    "       \n",
    "        cdef long previous_mode = self.mode_labels[i]\n",
    "        cdef long best_mode,accepted = 0       \n",
    "        best_mode = self.closest_mode(i,self.modes)\n",
    "        \n",
    "        if best_mode != previous_mode:\n",
    "            self.clusters[best_mode].insert(i)\n",
    "            self.clusters[previous_mode].erase(i)\n",
    "            self.mode_labels[i] = best_mode\n",
    "            self.cluster_sizes[previous_mode] -= 1.\n",
    "            self.cluster_sizes[best_mode] += 1.\n",
    "            accepted = 0\n",
    "      \n",
    "        return accepted\n",
    "    \n",
    "    cdef long merge_move(self):\n",
    "        \"\"\"\n",
    "        perform move type 2 for two random modes\n",
    "        \"\"\"\n",
    "        cdef long accepted = 0,i,mode1,mode2,rand,merged_mode,m\n",
    "        cdef cpp_vector[long] modes_vector\n",
    "        cdef unordered_set[long] merged_cluster\n",
    "        cdef cpp_vector[double] old_sizes\n",
    "        cdef cpp_vector[double] new_sizes\n",
    "        cdef double DL_before,DL_after\n",
    "        \n",
    "        if self.K == 1:\n",
    "            return 0\n",
    "\n",
    "        for m in self.modes:\n",
    "            modes_vector.push_back(m)\n",
    "            old_sizes.push_back(self.cluster_sizes[m])\n",
    "\n",
    "        rand = random_int(0,self.K - 1)\n",
    "        mode1 = modes_vector[rand]\n",
    "        rand = random_int(0,self.K - 1)\n",
    "        mode2 = modes_vector[rand]\n",
    "        while mode2 == mode1:\n",
    "            rand = random_int(0,self.K - 1)\n",
    "            mode2 = modes_vector[rand]\n",
    "            \n",
    "        DL_before = self.cluster_DL(mode1,self.clusters[mode1],0) + self.cluster_DL(mode2,self.clusters[mode2],0) \\\n",
    "                        + self.sizes_DL(self.K,old_sizes)\n",
    "        merged_cluster = set_merge(self.clusters[mode1],self.clusters[mode2])\n",
    "        merged_mode = self.mc_centroid(merged_cluster)\n",
    "        for m in self.modes:\n",
    "            if (m != mode1) and (m != mode2):\n",
    "                new_sizes.push_back(self.cluster_sizes[m])\n",
    "        new_sizes.push_back(float(merged_cluster.size()))\n",
    "        DL_after = self.cluster_DL(merged_mode,merged_cluster,0) + self.sizes_DL(self.K-1,new_sizes)\n",
    "        \n",
    "        if (DL_after - DL_before) < 0:\n",
    "            \n",
    "            self.clusters.erase(mode1)\n",
    "            self.clusters.erase(mode2)\n",
    "            self.modes.erase(mode1)\n",
    "            self.modes.erase(mode2)\n",
    "            self.modes.insert(merged_mode)\n",
    "            self.clusters[merged_mode] = merged_cluster\n",
    "            for i in merged_cluster:\n",
    "                self.mode_labels[i] = merged_mode\n",
    "            self.DL += DL_after - DL_before\n",
    "            self.K -= 1\n",
    "            self.cluster_sizes.erase(mode1)\n",
    "            self.cluster_sizes.erase(mode2)\n",
    "            self.cluster_sizes[merged_mode] = float(merged_cluster.size())\n",
    "            accepted = 1\n",
    "        \n",
    "        return accepted\n",
    "    \n",
    "    cdef long split_move(self,long max_local_moves):\n",
    "        \"\"\"\n",
    "        perform move type 3 for a random mode\n",
    "        stop local K-medoids if exceeds 'max_local_moves' iterations\n",
    "        \"\"\"\n",
    "        cdef long accepted = 0,i,mode,rand,num_parts,m,index,best\n",
    "        cdef cpp_vector[long] cluster_vector\n",
    "        cdef cpp_vector[long] modes_vector\n",
    "        cdef double DL_before,DL_after\n",
    "        cdef long new_mode1,new_mode2,old\n",
    "        cdef unordered_set[long] new_modes\n",
    "        cdef unordered_set[long] previous_modes\n",
    "        cdef cpp_map[long,unordered_set[long]] new_clusters\n",
    "        cdef unordered_set[long] dummy\n",
    "        cdef unordered_set[long] cluster \n",
    "        cdef cpp_vector[double] old_sizes\n",
    "        cdef cpp_vector[double] new_sizes\n",
    "        cdef long[:] new_labels = cvarray(shape=(self.n_samples,), itemsize=sizeof(long), format=\"l\")\n",
    "        \n",
    "        for m in self.modes:\n",
    "            modes_vector.push_back(m)\n",
    "            old_sizes.push_back(self.cluster_sizes[m])\n",
    "            \n",
    "        rand = random_int(0,self.K - 1)\n",
    "        mode = modes_vector[rand]\n",
    "        cluster = self.clusters[mode]\n",
    "        num_parts = cluster.size()\n",
    "        while num_parts < 2:\n",
    "            rand = random_int(0,self.K - 1)\n",
    "            mode = modes_vector[rand]\n",
    "            cluster = self.clusters[mode]\n",
    "            num_parts = cluster.size()\n",
    "        \n",
    "        for i in cluster:\n",
    "            cluster_vector.push_back(i)\n",
    "        DL_before = self.cluster_DL(mode,cluster,0)  + self.sizes_DL(self.K,old_sizes) \n",
    "        \n",
    "        rand = random_int(0,num_parts - 1)\n",
    "        new_mode1 = cluster_vector[rand]\n",
    "        rand = random_int(0,num_parts - 1)\n",
    "        new_mode2 = cluster_vector[rand]\n",
    "        while new_mode2 == new_mode1:\n",
    "            rand = random_int(0,num_parts - 1)\n",
    "            new_mode2 = cluster_vector[rand] \n",
    "        new_modes.insert(new_mode1)\n",
    "        new_modes.insert(new_mode2)\n",
    "        new_clusters[new_mode1] = dummy\n",
    "        new_clusters[new_mode2] = dummy\n",
    "        \n",
    "        for i in cluster:\n",
    "            best = self.closest_mode(i,new_modes)\n",
    "            new_clusters[best].insert(i)\n",
    "            new_labels[i] = best\n",
    "        \n",
    "        for index in range(max_local_moves):\n",
    "            \n",
    "            previous_modes = new_modes\n",
    "            for m in previous_modes:\n",
    "                cluster = new_clusters[m]\n",
    "                best = self.mc_centroid(cluster)\n",
    "                for i in cluster:\n",
    "                    new_labels[i] = best\n",
    "                new_clusters.erase(m)\n",
    "                new_modes.erase(m)   \n",
    "                new_clusters[best] = cluster\n",
    "                new_modes.insert(best)\n",
    "            \n",
    "            for i in cluster:\n",
    "                best = self.closest_mode(i,new_modes)\n",
    "                old = new_labels[i]\n",
    "                new_clusters[old].erase(i)\n",
    "                new_clusters[best].insert(i)\n",
    "                new_labels[i] = best\n",
    "        \n",
    "        DL_after = 0.\n",
    "        modes_vector.clear()\n",
    "        for m in new_modes:\n",
    "            DL_after += self.cluster_DL(m,new_clusters[m],0)\n",
    "            modes_vector.push_back(m)\n",
    "            new_sizes.push_back(float(new_clusters[m].size()))\n",
    "        for m in self.modes:\n",
    "            if m != mode:\n",
    "                new_sizes.push_back(self.cluster_sizes[m])\n",
    "        DL_after += self.sizes_DL(self.K+1,new_sizes)\n",
    "\n",
    "        if ((DL_after - DL_before) < 0) and (self.VI_w_mat(modes_vector[0],modes_vector[1]) > self.mode_scale):\n",
    "            self.modes.erase(mode)\n",
    "            self.clusters.erase(mode)\n",
    "            self.K += 1\n",
    "            self.cluster_sizes.erase(mode)\n",
    "            for m in new_modes:\n",
    "                self.modes.insert(m)\n",
    "                self.clusters[m] = new_clusters[m]\n",
    "                for i in self.clusters[m]:\n",
    "                    self.mode_labels[i] = m\n",
    "                self.cluster_sizes[m] = float(self.clusters[m].size())\n",
    "            accepted = 1\n",
    "        \n",
    "        return accepted\n",
    "\n",
    "    cdef long merge_split_move(self,long max_local_moves): \n",
    "        \"\"\"\n",
    "        perform move type 2 for a random pair of modes, then a move of type 3 for this newly merged mode\n",
    "        stop local K-medoids if exceeds 'max_local_moves' iterations\n",
    "        \"\"\"\n",
    "        cdef long accepted = 0,i,old_mode1,old_mode2,rand,num_parts,m,index,best\n",
    "        cdef cpp_vector[long] cluster_vector\n",
    "        cdef cpp_vector[long] modes_vector\n",
    "        cdef double DL_before,DL_after\n",
    "        cdef long new_mode1,new_mode2,old\n",
    "        cdef unordered_set[long] new_modes\n",
    "        cdef unordered_set[long] previous_modes\n",
    "        cdef cpp_map[long,unordered_set[long]] new_clusters\n",
    "        cdef unordered_set[long] dummy\n",
    "        cdef unordered_set[long] cluster \n",
    "        cdef cpp_vector[double] old_sizes\n",
    "        cdef cpp_vector[double] new_sizes \n",
    "        cdef long[:] new_labels = cvarray(shape=(self.n_samples,), itemsize=sizeof(long), format=\"l\")\n",
    "        \n",
    "        if self.K == 1:\n",
    "            return 0\n",
    "        \n",
    "        for m in self.modes:\n",
    "            modes_vector.push_back(m)\n",
    "            old_sizes.push_back(self.cluster_sizes[m])\n",
    "        \n",
    "        rand = random_int(0,self.K - 1)\n",
    "        old_mode1 = modes_vector[rand]\n",
    "        rand = random_int(0,self.K - 1)\n",
    "        old_mode2 = modes_vector[rand]\n",
    "        while old_mode2 == old_mode1:\n",
    "            rand = random_int(0,self.K - 1)\n",
    "            old_mode2 = modes_vector[rand]\n",
    "        DL_before = self.cluster_DL(old_mode1,self.clusters[old_mode1],0) \\\n",
    "                  + self.cluster_DL(old_mode2,self.clusters[old_mode2],0)\\\n",
    "                  + self.sizes_DL(self.K,old_sizes)\n",
    "        cluster = set_merge(self.clusters[old_mode1],self.clusters[old_mode2])\n",
    "        num_parts = cluster.size()\n",
    "        \n",
    "        for i in cluster:\n",
    "            cluster_vector.push_back(i)\n",
    "        \n",
    "        rand = random_int(0,num_parts - 1)\n",
    "        new_mode1 = cluster_vector[rand]\n",
    "        rand = random_int(0,num_parts - 1)\n",
    "        new_mode2 = cluster_vector[rand]\n",
    "        while new_mode2 == new_mode1:\n",
    "            rand = random_int(0,num_parts - 1)\n",
    "            new_mode2 = cluster_vector[rand] \n",
    "        new_modes.insert(new_mode1)\n",
    "        new_modes.insert(new_mode2)\n",
    "        new_clusters[new_mode1] = dummy\n",
    "        new_clusters[new_mode2] = dummy\n",
    "        \n",
    "        for i in cluster:\n",
    "            best = self.closest_mode(i,new_modes)\n",
    "            new_clusters[best].insert(i)\n",
    "            new_labels[i] = best\n",
    "        \n",
    "        for index in range(max_local_moves):\n",
    "            \n",
    "            previous_modes = new_modes\n",
    "            for m in previous_modes:\n",
    "                cluster = new_clusters[m]\n",
    "                best = self.mc_centroid(cluster)\n",
    "                for i in cluster:\n",
    "                    new_labels[i] = best\n",
    "                new_clusters.erase(m)\n",
    "                new_modes.erase(m)   \n",
    "                new_clusters[best] = cluster\n",
    "                new_modes.insert(best)\n",
    "            \n",
    "            for i in cluster:\n",
    "                best = self.closest_mode(i,new_modes)\n",
    "                old = new_labels[i]\n",
    "                new_clusters[old].erase(i)\n",
    "                new_clusters[best].insert(i)\n",
    "                new_labels[i] = best\n",
    "            \n",
    "        DL_after = 0.\n",
    "        modes_vector.clear()\n",
    "        for m in new_modes:\n",
    "            DL_after += self.cluster_DL(m,new_clusters[m],0)\n",
    "            new_sizes.push_back(float(new_clusters[m].size()))\n",
    "            modes_vector.push_back(m)\n",
    "        for m in self.modes:\n",
    "            if (m != old_mode1) and (m != old_mode2):\n",
    "                new_sizes.push_back(self.cluster_sizes[m])\n",
    "        DL_after += self.sizes_DL(self.K,new_sizes)\n",
    "\n",
    "        if ((DL_after - DL_before) < 0) and (self.VI_w_mat(modes_vector[0],modes_vector[1]) > self.mode_scale):\n",
    "            self.modes.erase(old_mode1)\n",
    "            self.clusters.erase(old_mode1)\n",
    "            self.cluster_sizes.erase(old_mode1)\n",
    "            self.modes.erase(old_mode2)\n",
    "            self.clusters.erase(old_mode2)\n",
    "            self.cluster_sizes.erase(old_mode2)\n",
    "            for m in new_modes:\n",
    "                self.modes.insert(m)\n",
    "                self.clusters[m] = new_clusters[m]\n",
    "                for i in self.clusters[m]:\n",
    "                    self.mode_labels[i] = m\n",
    "                self.cluster_sizes[m] = float(self.clusters[m].size())\n",
    "            accepted = 1\n",
    "        \n",
    "        return accepted\n",
    "\n",
    "    \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.nonecheck(False)       \n",
    "cpdef partition_clustering_cython(long[:,:] partitions,double[:] energies,long num_mcs,long num_init_modes,long initial_runs,\\\n",
    "                               double manual_mode_scale,double dist_percentile,long fix_K,long consecutive_rejects,\\\n",
    "                                 long max_local_moves,double Lambda,long Kprior,long MItype,long mode_info_type):\n",
    "    \"\"\"\n",
    "    run clustering algorithm using 'clustering_state' class defined above\n",
    "    inputs:\n",
    "        'fix_K': fix number of clusters at K0 by only performing moves 1 and 4\n",
    "        'consecutive_rejects': number of failed moves before terminating the algorithm\n",
    "         all other variables defined in 'clustering_state' class methods\n",
    "    writes to file 'tmp.txt' in local folder to track progress of algorithm (can comment this out if not needed)\n",
    "    returns:\n",
    "        modes (partition indices)\n",
    "        clusters (sets of partition indices)\n",
    "        mode_labels (label of mode for each partition, in order of partition index)\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef long runct = 0,num_rejects = 0,accepted,move,i\n",
    "    cdef double[:] type_probs\n",
    "    \n",
    "    if fix_K == 1:\n",
    "        type_probs = np.array([0.5,0.,0.,0.5]).astype('float')   \n",
    "    else:\n",
    "        type_probs = np.array([0.25,0.25,0.25,0.25]).astype('float')\n",
    "    f = open('tmp.txt', 'a'); f.write('Starting.... \\n'); f.close()\n",
    "    state = clustering_state(partitions,energies,num_mcs,Lambda,Kprior,MItype,mode_info_type)\n",
    "    f = open('tmp.txt', 'a'); f.write('A:'+str(state.partition_entropies)+' \\n'); f.close()\n",
    "    state.initalize_cluster_data(num_init_modes,initial_runs)\n",
    "    f = open('tmp.txt', 'a'); f.write('B:'+str(list(state.modes))+' \\n'); f.close()\n",
    "    state.compute_full_DL()\n",
    "    f = open('tmp.txt', 'a'); f.write('C:'+str(state.DL)+' \\n'); f.close()\n",
    "    state.initialize_mode_scale(dist_percentile,manual_mode_scale)\n",
    "    f = open('tmp.txt', 'a'); f.write('D:'+str(state.mode_scale)+' \\n'); f.close()\n",
    "        \n",
    "    while num_rejects < consecutive_rejects:\n",
    "        move = categorical(type_probs)\n",
    "        if move == 0:\n",
    "            i = random_int(0,state.n_samples-1)\n",
    "            accepted = state.closest_mode_move(i)\n",
    "            \n",
    "        elif move == 1:\n",
    "            accepted = state.merge_move()\n",
    "            \n",
    "        elif move == 2:\n",
    "            accepted = state.split_move(max_local_moves)\n",
    "            \n",
    "        elif move == 3:\n",
    "            accepted = state.merge_split_move(max_local_moves)\n",
    "            \n",
    "        if accepted == 0:\n",
    "            num_rejects += 1\n",
    "        else:\n",
    "            num_rejects = 0\n",
    "            \n",
    "        f = open('tmp.txt', 'a'); f.write('Move:'+str(move)+', Acc:'+str(accepted)+\\\n",
    "                                          ', Modes:'+str(list(state.modes))+\\\n",
    "                                          ', Sizes:'+str(dict(state.cluster_sizes))+' \\n'); f.close()\n",
    "        \n",
    "                 \n",
    "    return state.modes,state.clusters,state.mode_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_clustering(g,partitions,energies,num_mcs,num_init_modes,initial_runs,\\\n",
    "                        manual_mode_scale,dist_percentile,fix_K,consecutive_rejects,max_local_moves,\\\n",
    "                         Lambda,Kprior,MItype,mode_info_type,\\\n",
    "                         graph_plots,node_size = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    partition clustering algorithm (wrapper for Cython code)\n",
    "    inputs:\n",
    "        'g': igraph network object\n",
    "        'graph_plots': plot output partitions using sknetwork (True/False)\n",
    "        'node_size': size of nodes in these plots\n",
    "         all other variables defined in Cython class and function definitions\n",
    "         \n",
    "    returns:\n",
    "        modes and mode_labels (as in Cython function)\n",
    "        g\n",
    "        length S list of length N partitions\n",
    "        partition log-probabilities \n",
    "    \"\"\"\n",
    "    \n",
    "    partitions = np.array(partitions).astype('int')\n",
    "    energies = np.array(energies).astype('float')\n",
    "    num_mcs,num_init_modes,initial_runs,manual_mode_scale,dist_percentile,fix_K,consecutive_rejects,\\\n",
    "                max_local_moves,Lambda,Kprior = \\\n",
    "         int(num_mcs),int(num_init_modes),int(initial_runs),float(manual_mode_scale),float(dist_percentile),\\\n",
    "        int(fix_K),int(consecutive_rejects),int(max_local_moves),float(Lambda),int(Kprior)\n",
    "    res = partition_clustering_cython(partitions,energies,num_mcs,num_init_modes,initial_runs,\\\n",
    "                               manual_mode_scale,dist_percentile,fix_K,consecutive_rejects,\\\n",
    "                                 max_local_moves,Lambda,Kprior,MItype,mode_info_type)\n",
    "    \n",
    "    modes = list(res[0])\n",
    "    if graph_plots == True: \n",
    "        g2 = pyg.igraph2gt(g)\n",
    "        pos = sfdp_layout(g2, multilevel=True, cooling_step=0.99)\n",
    "        x, y = ungroup_vector_property(pos, [0, 1])\n",
    "        g.vs['x'] = list(x.a)\n",
    "        g.vs['y'] = list(y.a)\n",
    "        print('-----------------------------------------------------------')\n",
    "        print('Plotting '+str(len(modes))+' representative partitions...')\n",
    "        print('----------------------------------------------------------- \\n')\n",
    "        weights = Counter(res[-1])\n",
    "        adjacency = ss.csr_matrix(g.get_adjacency().data)\n",
    "        for m in modes:\n",
    "            print('Partition index:',m,', Partition log-probability:',energies[m],', Weight:',weights[m]/len(energies))\n",
    "            partition_labels = np.array(gt.inference.partition_modes.align_partition_labels(partitions[m],\\\n",
    "                                                                partitions[modes[0]])).astype('int')\n",
    "            image = sknetwork.visualization.svg_graph(adjacency,position = np.array([g.vs['x'],g.vs['y']]).T,scale=1, \\\n",
    "                                                      node_size=node_size,labels = partition_labels)\n",
    "                \n",
    "            display(SVG(image))\n",
    "    \n",
    "    mode_labels = list(res[2])\n",
    "    return modes,mode_labels,g,partitions,energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "g: igraph object\n",
    "partitions: S by N array of node community labels\n",
    "    useful package for a variety of community sampling methods is 'graph_tool'\n",
    "energies: partition log-probabilities (simply used to check for duplicate partitions)\n",
    "num_mcs: number of MCMC moves to use for estimating local modes\n",
    "num_init_modes: number of inotial modes K0\n",
    "initial_runs: number of runns to do for initialization of K0 modes through K-medoids-type clustering\n",
    "manual_mode_scale,dist_percentile: not used in current version of algorithm, can ignore and set to -1\n",
    "fix_K: 0 = standard algorithm, 1 = only use moves 1 and 4 to keep K the same\n",
    "consecutive_rejects: number of consecutive rejected moves before terminating algorithm\n",
    "max_local_moves: maximum number of iterations to do for local K-medoids type clustering during split moves\n",
    "Lambda: linear penalty on K\n",
    "graph_plots: True/False, whether or not to plot network with mode partitions\n",
    "node_size: size of nodes in such plots\n",
    "'Lambda': linear penalty for K. set to zero for standard description length\n",
    "'Kprior': 0 gives no penalty on K; 1 gives linear penalty on K of size Lambda (used in paper); 2 gives log(K) penalty\n",
    "'MItype': 0 gives regular mutual information, 1 gives reduced mutual information (used in paper)\n",
    "'mode_info_type': 0 gives entropy penalty (used in paper); 1 gives less efficient fixed-length code penalty \n",
    "\"\"\"\n",
    "\n",
    "results = partition_clustering(g,partitions,energies, num_mcs = 30,num_init_modes = 1,initial_runs = 10,\\\n",
    "                manual_mode_scale = -1.,dist_percentile = -1.,fix_K = 0,consecutive_rejects = 100,\\\n",
    "                        max_local_moves = 10,Lambda = 0.,graph_plots = True,node_size = 5,Kprior=1,MItype=1,mode_info_type=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
